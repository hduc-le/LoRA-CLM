# model config
save_name: "lora-dolly-v2-3b"
model_name_or_path: "databricks/dolly-v2-3b"

# optimizer config
learning_rate: 2.0e-5
weight_decay: 0.0
gradient_checkpointing: true
gradient_accumulation_steps: 2
lr_scheduler: null
ExponentialLR_gamma: 0.96

# training config
lora: true             # set `False` for fully fine-tuning
load_8bit: false                
num_epochs: 5
save_model: 1
save_best: true
patience: 5
show_progress_bar: true
push_to_hub: false  
huggingface_hub: ### SETUP if needed

# data config
data_path: ### SETUP
cutoff_len: 512
train_bsz: 4
test_bsz: 4
test_ratio: 0.2

# LoRA config
lora_r: 4
lora_alpha: 16
lora_dropout: 0.05