save_name: "model-lora"
model_name_or_path: "databricks/dolly-v2-3b"

# optimizer config
learning_rate: 2e-5
weight_decay: 1e-4
lr_scheduler: "ExponentialLR"
ExponentialLR_gamma: 0.96

# training config
lora_finetune: True             # set `False` for fully fine-tuning
load_8bit: False                # load model as 8bit might cause some unexpected errors
num_epochs: 5
save_model: 1
save_best: True
patience: 5
show_progress_bar: True
push_to_hub: False  
huggingface_hub: ""

# data config
data_path: "/path/to/json/data.json"
cutoff_len: 512
train_bsz: 4
test_bsz: 4
test_ratio: 0.2

# LoRA config
lora_r: 4
lora_alpha: 16
lora_dropout: 0.05